{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as t\n",
    "\n",
    "from gulpio2 import GulpDirectory\n",
    "from pathlib import Path\n",
    "from moviepy.editor import ImageSequenceClip, clips_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch intro (already know all of this)\n",
    "\n",
    "basic understanding of creating and manipulating tensors, as well as converting them between the torch an numpy libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = t.load('../models/trn_rgb.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "\n",
    "x_data = t.tensor(data)\n",
    "\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = t.from_numpy(np_array)\n",
    "\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ones = t.ones_like(x_data)\n",
    "\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9567, 0.1242],\n",
       "        [0.5955, 0.9702]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rand = t.rand_like(x_data, dtype=t.float)\n",
    "\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2603, 0.0285, 0.3682],\n",
       "         [0.2309, 0.1206, 0.9349]]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "\n",
    "t_rand = t.rand(shape)\n",
    "t_ones = t.ones(shape)\n",
    "t_zero = t.zeros(shape)\n",
    "\n",
    "t_rand, t_ones, t_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = t.rand(3,4)\n",
    "\n",
    "tensor.shape, tensor.dtype, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we move our tensor to the GPU if available\n",
    "if t.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    \n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard indexing and slicing\n",
    "\n",
    "tensor = t.ones(4,4)\n",
    "\n",
    "tensor[:,1] = 0\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = t.cat([t.ones(4,1),t.ones(4,1)*2,t.ones(4,1)*3,t.ones(4,1)*4],dim=1)\n",
    "\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.],\n",
       "        [8.],\n",
       "        [8.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = t.ones(4,1) * 2\n",
    "t2 = t.ones(4,1) * 4\n",
    "\n",
    "t1 * t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 8., 8., 8.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [8., 8., 8., 8.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose one since malmut needs t.shape (4,1) and (1,4)\n",
    "\n",
    "t_x = t1 @ t2.T\n",
    "\n",
    "t_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13., 13., 13., 13.],\n",
       "        [13., 13., 13., 13.],\n",
       "        [13., 13., 13., 13.],\n",
       "        [13., 13., 13., 13.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operations with _ suffix are inplace, saving memory but may be destructive due to immediate memory loss\n",
    "\n",
    "t_x.add_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13., 13., 13., 13.],\n",
       "       [13., 13., 13., 13.],\n",
       "       [13., 13., 13., 13.],\n",
       "       [13., 13., 13., 13.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor vs numpy\n",
    "\n",
    "n_x = t_x.numpy()\n",
    "\n",
    "n_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 8., 8., 8.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [8., 8., 8., 8.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a change in the tensor, reflects \n",
    "\n",
    "t_x.sub_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8., 8., 8., 8.],\n",
       "       [8., 8., 8., 8.],\n",
       "       [8., 8., 8., 8.],\n",
       "       [8., 8., 8., 8.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "\n",
    "n = np.ones([4,4])\n",
    "\n",
    "t_n = t.from_numpy(n)\n",
    "t_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_n.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "[[6. 6.]\n",
      " [6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "x = t.ones(2,2)\n",
    "print(x)\n",
    "\n",
    "x.add_(5)\n",
    "n = x.numpy()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to `TORCH.AUTOGRAD`\n",
    "\n",
    "- backward and forward propagation for a pretrained model on a tensor from an epic video tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "gulp_root = Path.home()\n",
    "rgb_train = GulpDirectory('../datasets/epic/gulp/rgb_p01/')\n",
    "rgb_frames, rgb_meta = rgb_train['P01_01_90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 256, 456, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_frames = t.tensor(rgb_frames)\n",
    "rgb_frames.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = rgb_frames[0].reshape(1,3,256,456)\n",
    "# data = t.rand(1,3,256,456)\n",
    "# labels = t.randint(256,(1,1000))\n",
    "labels = t.rand(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.float()\n",
    "pred = model(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (pred - labels).sum()\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = t.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1,6,3)\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "        # an affinite operation: y= Wx + b\n",
    "        self.fc1 = nn.Linear(16*6*6,120) # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2,2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        # If the image size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for x in size:\n",
    "            num_features *= x\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, torch.Size([6, 1, 3, 3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params), params[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = t.randn(1,1,32,32)\n",
    "\n",
    "out = net(data)\n",
    "\n",
    "net.zero_grad()\n",
    "out.backward(t.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = t.randn(3,1920,1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1397,  0.5502,  1.6300,  ...,  0.9398, -0.0719, -2.2812],\n",
       "         [-0.2084, -0.4688,  0.9950,  ...,  1.1666, -1.1199,  0.6802],\n",
       "         [-1.1255,  1.5349,  0.4463,  ...,  0.1691,  0.4356, -0.1499],\n",
       "         ...,\n",
       "         [-0.1423, -1.9227, -1.1938,  ..., -0.3782, -0.7625,  0.3316],\n",
       "         [-0.4834, -0.2956,  0.9604,  ...,  1.8837, -0.0243,  1.7543],\n",
       "         [ 0.6476, -1.7784,  1.1157,  ...,  0.2569,  0.1327, -0.1933]],\n",
       "\n",
       "        [[ 1.2829,  1.1765,  0.1958,  ..., -1.5732,  0.1448, -1.2092],\n",
       "         [-0.6557, -0.3134,  0.1925,  ...,  2.2321, -0.1551,  0.8474],\n",
       "         [-0.8401,  0.7711, -1.9645,  ..., -0.9020, -1.7128,  2.1805],\n",
       "         ...,\n",
       "         [-0.5909,  1.0970,  0.9628,  ..., -0.8758,  1.2320, -1.2602],\n",
       "         [-1.3636,  0.3095,  1.3150,  ...,  0.4650,  0.4415,  0.6542],\n",
       "         [ 0.8892,  1.1601, -0.4193,  ..., -0.4005, -0.2716,  2.7571]],\n",
       "\n",
       "        [[-0.2225, -0.3776,  1.8823,  ..., -0.1462,  0.1571,  0.1435],\n",
       "         [-0.3925, -0.2903, -0.0522,  ..., -0.2563, -0.2271,  0.0597],\n",
       "         [-1.1133,  0.0720, -0.3651,  ..., -0.8201,  0.7371,  0.4579],\n",
       "         ...,\n",
       "         [ 0.1269, -0.9771,  0.5398,  ..., -0.9633, -0.7164, -1.1252],\n",
       "         [-0.8351, -2.1579,  0.3479,  ..., -0.3540,  2.1977, -0.3643],\n",
       "         [ 1.2731,  1.7397, -1.4400,  ...,  1.6981,  0.2489, -0.8367]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
