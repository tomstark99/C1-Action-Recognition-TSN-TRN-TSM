{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset demonstration\n",
    "\n",
    "This notebook shows you how to read the data using GulpIO and visualise the frames (both RGB and optical flow U/V pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gulpio2 import GulpDirectory\n",
    "from pathlib import Path\n",
    "from moviepy.editor import ImageSequenceClip, clips_array\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import colorlog\n",
    "import torch as t\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_lightning import Callback, Trainer\n",
    "from typing import Any, Dict, List, Sequence, Union\n",
    "\n",
    "from systems import EpicActionRecogintionDataModule\n",
    "from systems import EpicActionRecognitionSystem\n",
    "\n",
    "from test import ResultsSaver\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP LOGGING\n",
    "LOG = logging.getLogger(\"test\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "handler = colorlog.StreamHandler()\n",
    "handler.setFormatter(colorlog.ColoredFormatter(\"%(log_color)s%(levelname)s:%(name)s:%(message)s\"))\n",
    "\n",
    "logger = colorlog.getLogger(\"example\")\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# SETUP TORCH VARIABLES\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "dtype = t.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:models.tsn:Initializing MTRN with base model: resnet50.\n",
      "\n",
      "MTRN Configuration:\n",
      "    input_modality:     RGB\n",
      "    num_segments:       8\n",
      "    segment_length:     1\n",
      "    consensus_module:   TRNMultiscale\n",
      "    img_feature_dim:    256 (only valid for TRN)\n",
      "    dropout_ratio:      0.7\n",
      "    partial_bn:         True\n",
      "        \n",
      "INFO:models.tsn:Loading backbone model with imagenet weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Scale Temporal Relation Network Module in use ['8-frame relation', '7-frame relation', '6-frame relation', '5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EpicActionRecognitionSystem(\n",
       "  (model): MTRN(\n",
       "    (base_model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Dropout(p=0.7, inplace=False)\n",
       "    )\n",
       "    (new_fc): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (consensus): RelationModuleMultiScale(\n",
       "      (fc_fusion_scales): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=397, bias=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Linear(in_features=1792, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=397, bias=True)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=397, bias=True)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Linear(in_features=1280, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=397, bias=True)\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=397, bias=True)\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Linear(in_features=768, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=397, bias=True)\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=397, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD IN SAVED CHECKPOINT\n",
    "ckpt = t.load('../models/trn_rgb.ckpt', map_location='cpu')\n",
    "\n",
    "# CREATE CONFIG FROM CHECKPOINT\n",
    "cfg = OmegaConf.create(ckpt['hyper_parameters'])\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "# SET GULP DIRECTORY\n",
    "cfg.data._root_gulp_dir = '/home/ts/C1-Action-Recognition-TSN-TRN-TSM/datasets/epic/gulp/rgb'\n",
    "\n",
    "# CREATE MODEL\n",
    "model = EpicActionRecognitionSystem(cfg)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR WHOLE GULPED DATA\n",
    "\n",
    "# if not cfg.get(\"log_graph\", True):\n",
    "#     try:\n",
    "#         delattr(system, \"example_input_array\")\n",
    "#     except AttributeError:\n",
    "#         pass\n",
    "\n",
    "# LOG.info(\"Disabling DP/DDP\")\n",
    "# cfg.trainer.accelerator = None\n",
    "    \n",
    "# n_gpus = 1\n",
    "\n",
    "# cfg.trainer.gpus = n_gpus\n",
    "# cfg['test.results_path'] = '../outputs/exp.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_module = EpicActionRecogintionDataModule(cfg)\n",
    "\n",
    "# dataloader = data_module.test_dataloader()\n",
    "\n",
    "# saver = ResultsSaver()\n",
    "\n",
    "# trainer = Trainer(**cfg.trainer, callbacks=[saver])\n",
    "# trainer.test(system, test_dataloaders=dataloader)\n",
    "# out = system.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET GULP ROOT FOR gulpio2\n",
    "gulp_root = Path.home()\n",
    "\n",
    "# LOAD GULPED DATA\n",
    "rgb_train = GulpDirectory('../datasets/epic/gulp/rgb/rgb_test/')#GulpDirectory('/home/will/P01_rgb_gulp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# flow_train = GulpDirectory('../datasets/epic/gulp/flow_train/')#GulpDirectory('/home/will/P01_flow_gulp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT SINGLE CLIP TO PROCESS (uncomment for full list of ids)\n",
    "# rgb_train.merged_meta_dict.keys()\n",
    "clip_id = 'P01_01_96'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FRAMES AND META FOR SELECTED VIDEO\n",
    "rgb_frames, rgb_meta = rgb_train[clip_id]\n",
    "# flow_frames, flow_meta = flow_train[clip_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE INPUT DATA FOR RUNNING THROUGH MODEL\n",
    "\n",
    "rgb_frames = np.array(rgb_frames).transpose(0,3,1,2)\n",
    "rgb_frames = t.tensor(rgb_frames, device=device, dtype=dtype)\n",
    "rgb_frames = rgb_frames.unsqueeze(0)\n",
    "\n",
    "# RUN FRAMES THROUGH MODEL\n",
    "with t.no_grad():\n",
    "    result = model.forward_tasks(rgb_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.pkl', 'wb') as f:\n",
    "  pickle.dump(result, f)\n",
    "# probs = t.softmax(result, -1)\n",
    "# pred_noun, pred_verb = out[:97].argmax().item(), out[97:].argmax().item()\n",
    "# pred_noun, pred_verb # = out[pred].item(), probs[pred].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_scores(scores: np.ndarray, top_n: int = 100):\n",
    "    if scores.ndim == 1:\n",
    "        top_n_idx = scores.argsort()[::-1][:top_n]\n",
    "        return top_n_idx, scores[top_n_idx]\n",
    "    else:\n",
    "        top_n_scores_idx = np.argsort(scores)[:,::-1][:top_n]#scores.argsort()[:,::-1][:,:top_n]\n",
    "        return top_n_scores_idx, scores[np.arrange(0, len(scores)).reshape(-1,1), top_n_scores_idx]\n",
    "    \n",
    "def compute_scores(verb_scores: np.ndarray, noun_scores: np.ndarray, top_n: int = 100):\n",
    "    top_verbs, top_verb_scores = top_scores(verb_scores, top_n)\n",
    "    top_nouns, top_noun_scores = top_scores(noun_scores, top_n)\n",
    "    top_verb_probs, top_noun_probs = softmax(top_verb_scores), softmax(top_noun_scores)\n",
    "    action_probs_matrix = (top_verb_probs[:,:,np.newaxis] * top_noun_probs[:,np.newaxis,:])\n",
    "    instance_count = action_probs_matrix.shape[0]\n",
    "    action_ranks = action_probs_matrix.reshape(instance_count, -1).argsort(axis=-1)[:,::-1]\n",
    "    verb_rans_idx, noun_ranks_idx = np.unravel_index(action_ranks[:,:top_n],shape=(action_probs_matrix[1:]))\n",
    "    segments = np.arrange(0, instance_count).reshape(-1,1)\n",
    "    \n",
    "    return ((top_verbs[segments, verb_ranks_idx], top_nouns[segments, noun_ranks_idx]), \n",
    "            action_probs_matrix.reshape(instance_count,-1)[segments,action_ranks[:,:top_n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "step must be greater than zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-3610e4baaa57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mverbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'noun'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-240-01e1fad18c57>\u001b[0m in \u001b[0;36mcompute_scores\u001b[0;34m(verb_scores, noun_scores, top_n)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverb_scores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoun_scores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtop_verbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_verb_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverb_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtop_nouns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_noun_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoun_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtop_verb_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_noun_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_verb_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_noun_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-240-01e1fad18c57>\u001b[0m in \u001b[0;36mtop_scores\u001b[0;34m(scores, top_n)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtop_n_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_n_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtop_n_scores_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#scores.argsort()[:,::-1][:,:top_n]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtop_n_scores_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n_scores_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: step must be greater than zero"
     ]
    }
   ],
   "source": [
    "# labels: pd.DataFrame = pd.read_pickle('../datasets/epic/labels/EPIC_100_validation.pkl')\n",
    "labels_path = '../datasets/epic/labels/'\n",
    "\n",
    "unseen_participants = pd.read_csv(labels_path+'EPIC_100_unseen_participant_ids_test.csv', index_col='participant_id').index.values\n",
    "tail_verb_classes = pd.read_csv(labels_path+'EPIC_100_tail_verbs.csv', index_col='verb').index.values\n",
    "tail_noun_classes = pd.read_csv(labels_path+'EPIC_100_tail_nouns.csv', index_col='noun').index.values\n",
    "\n",
    "result\n",
    "(verbs, nouns), _scores = compute_scores(result['verb'].cpu(), result['noun'].cpu(), top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rgb(rgb_frames, fps=50):\n",
    "    return ImageSequenceClip(rgb_frames, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_flow(flow_frames, fps=50):\n",
    "    u_frames = flow_frames[::2]\n",
    "    v_frames = flow_frames[1::2]\n",
    "    \n",
    "    def flow_to_clip(flow):\n",
    "        # Convert optical flow magnitude to greyscale RGB\n",
    "        return ImageSequenceClip(list(np.stack([flow] * 3, axis=-1)), fps=fps)\n",
    "    \n",
    "    u_clip = flow_to_clip(u_frames) \n",
    "    v_clip = flow_to_clip(v_frames) \n",
    "    return clips_array([[u_clip, v_clip]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clips_array([[display_rgb(rgb_frames), display_flow(flow_frames)]]).ipython_display()\n",
    "display_rgb(rgb_frames).ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'narration_id': 'P01_01_96',\n",
       " 'participant_id': 'P01',\n",
       " 'video_id': 'P01_01',\n",
       " 'narration_timestamp': '00:07:46.520',\n",
       " 'start_timestamp': '00:07:49.14',\n",
       " 'stop_timestamp': '00:07:50.32',\n",
       " 'start_frame': 28148,\n",
       " 'stop_frame': 28219,\n",
       " 'narration': 'take glass',\n",
       " 'verb': 'take',\n",
       " 'verb_class': 0,\n",
       " 'noun': 'glass',\n",
       " 'noun_class': 10,\n",
       " 'all_nouns': ['glass'],\n",
       " 'all_noun_classes': [10],\n",
       " 'frame_size': [256, 456, 3],\n",
       " 'num_frames': 72}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = 'P01_06_90'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_frames, rgb_meta = rgb_train[clip_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_frames, flow_meta = flow_train[clip_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_array([[display_rgb(rgb_frames, fps=60), display_flow(flow_frames, fps=30)]]).ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
