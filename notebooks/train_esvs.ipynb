{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler, Subset\n",
    "\n",
    "from systems import EpicActionRecogintionShapleyClassifier\n",
    "\n",
    "from models.esvs import Net\n",
    "from datasets.pickle_dataset import PickleDataset\n",
    "from frame_sampling import RandomSampler\n",
    "\n",
    "from ipdb import launch_ipdb_on_exception\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "n_frames = 4\n",
    "pickle_dir = '../datasets/epic/features/p01_features.pkl'\n",
    "log_interval = 500\n",
    "\n",
    "frame_sampler = RandomSampler(frame_count=n_frames, snippet_length=1, test=False)\n",
    "dataset = PickleDataset(pickle_dir, frame_sampler)\n",
    "\n",
    "writer = SummaryWriter('runs/epic_all_models_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Net(frame_count=n_frames).to(device)\n",
    "\n",
    "lr = {\n",
    "    1e-3: [],\n",
    "    1e-4: [], \n",
    "    1e-5: []\n",
    "}\n",
    "\n",
    "for l in lr.keys():\n",
    "    loss_b = []\n",
    "    for b in batch_size:\n",
    "        dataloader = DataLoader(dataset, batch_size=b, shuffle=True)\n",
    "        data = iter(dataloader)\n",
    "        inputs = data.next()\n",
    "\n",
    "        optimiser = SGD(model.parameters(), lr=l, momentum=0.9)\n",
    "        classifier = EpicActionRecogintionShapleyClassifier(model, dataloader, optimiser, device, log_interval=log_interval)\n",
    "        running_loss = 0.0\n",
    "        training_loss = []\n",
    "        for i in range(5000):\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            step = classifier._step(inputs)\n",
    "\n",
    "            loss = step['loss']\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "    #         print(f'iter: {i}, 'f'loss: {loss.item()}')\n",
    "            running_loss += loss.item()\n",
    "            training_loss.append([i, loss.item()])\n",
    "\n",
    "            if i % log_interval == log_interval-1:\n",
    "                print('%5d) loss: %.3f' % (i + 1, running_loss / log_interval))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        loss_b.append(np.array(training_loss))\n",
    "    lr[l] = loss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for l, lss in lr.items():\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    for i, ls in enumerate(lss):\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=ls[:,0],\n",
    "            y=ls[:,1],\n",
    "    #         line_shape='spline',\n",
    "            name=f'batch_size: {batch_size[i]}'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title='batched steps',\n",
    "        yaxis_title='loss',\n",
    "        title=f'Training loss for lr: {l}',\n",
    "        yaxis_range=[-4, 2]\n",
    "    )\n",
    "    fig.update_yaxes(type=\"log\")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running training loop over whole dataset with\n",
    "\n",
    "`torch.optim.Adam(model.parameters(), lr = 1e-4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "############## split ##################\n",
    "validation_split = 0.2\n",
    "idxs = list(range(len(dataset)))\n",
    "split = int(np.floor(validation_split * len(dataset)))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_idx, test_idx = idxs[split:], idxs[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "################################\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "\n",
    "# log_interval = round(len(dataloader) / batch_size)\n",
    "# log_interval = 10\n",
    "\n",
    "model = Net(frame_count=n_frames).to(device)\n",
    "optimiser = Adam(model.parameters(), lr=3e-4)\n",
    "classifier = EpicActionRecogintionShapleyClassifier(model, device, optimiser, train_loader, test_loader, log_interval=log_interval)\n",
    "training_loss = {\n",
    "    'loss': [],\n",
    "    'acc1': [],\n",
    "    'acc5': [],\n",
    "}\n",
    "testing_loss = {\n",
    "    'loss': [],\n",
    "    'acc1': [],\n",
    "    'acc5': [],\n",
    "}\n",
    "for epoch in range(2000):\n",
    "    logs = {}\n",
    "    running_loss = 0.0\n",
    "    running_acc1 = 0.0\n",
    "    running_acc5 = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        optimiser.zero_grad()\n",
    "        step = classifier._step(data)\n",
    "\n",
    "        loss = step['loss']\n",
    "        acc1 = step['verb_accuracy@1']\n",
    "        acc5 = step['verb_accuracy@5']\n",
    "        \n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc1 += acc1.item()\n",
    "        running_acc5 += acc5.item()\n",
    "        training_loss['loss'].append(loss.item())\n",
    "        training_loss['acc1'].append(acc1.item())\n",
    "        training_loss['acc5'].append(acc5.item())\n",
    "        \n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc1 = running_acc1 / len(train_loader)\n",
    "    epoch_acc5 = running_acc5 / len(train_loader)\n",
    "\n",
    "    logs['loss'] = epoch_loss\n",
    "    logs['accuracy'] = epoch_acc1\n",
    "    logs['accuracy_5'] = epoch_acc5\n",
    "    \n",
    "    writer.add_scalar('loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('acc1', epoch_acc1, epoch)\n",
    "    writer.add_scalar('acc5', epoch_acc5, epoch)\n",
    "    \n",
    "    t_running_loss = 0.0\n",
    "    t_running_acc1 = 0.0\n",
    "    t_running_acc5 = 0.0\n",
    "    \n",
    "    for batch_idx, test_data in enumerate(test_loader):\n",
    "        \n",
    "        step = classifier._step(data)\n",
    "        \n",
    "        loss = step['loss']\n",
    "        acc1 = step['verb_accuracy@1']\n",
    "        acc5 = step['verb_accuracy@5']\n",
    "        \n",
    "        t_running_loss += loss.item()\n",
    "        t_running_acc1 += acc1.item()\n",
    "        t_running_acc5 += acc5.item()\n",
    "        testing_loss['loss'].append(loss.item())\n",
    "        testing_loss['acc1'].append(acc1.item())\n",
    "        testing_loss['acc5'].append(acc5.item())\n",
    "        \n",
    "    t_epoch_loss = t_running_loss / len(test_loader)\n",
    "    t_epoch_acc1 = t_running_acc1 / len(test_loader)\n",
    "    t_epoch_acc5 = t_running_acc5 / len(test_loader)\n",
    "    \n",
    "    logs['val_loss'] = t_epoch_loss\n",
    "    logs['val_accuracy'] = t_epoch_acc1\n",
    "    logs['val_accuracy_5'] = t_epoch_acc5\n",
    "    \n",
    "    writer.add_scalar('t_loss', t_epoch_loss, epoch)\n",
    "    writer.add_scalar('t_acc1', t_epoch_acc1, epoch)\n",
    "    writer.add_scalar('t_acc5', t_epoch_acc5, epoch)\n",
    "        \n",
    "    liveloss.update(logs)\n",
    "    liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "\n",
    "# for i, cl in enumerate(computed_loss):\n",
    "#     x = np.linspace(1, len(cl), len(cl), dtype=int)\n",
    "    \n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=x,\n",
    "#         y=cl,\n",
    "#         name=f'lr: {lr[i]}'\n",
    "#     ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     xaxis_title='batched steps',\n",
    "#     yaxis_title='loss',\n",
    "#     title=f'Training loss for lr: {1e-4}'\n",
    "# )\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "# fig.show()\n",
    "import pickle\n",
    "with open('../datasets/epic/models/4-frame_training_loss.pkl', 'wb') as f:\n",
    "    pickle.dump(training_loss, f)\n",
    "    \n",
    "with open('../datasets/epic/models/4-frame_testing_loss.pkl', 'wb') as f:\n",
    "    pickle.dump(testing_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "y = [cl[-1] for cl in computed_loss]\n",
    "        \n",
    "fig.add_trace(go.Scatter(\n",
    "    x=lr,\n",
    "    y=y\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='learning rate',\n",
    "    yaxis_title='min_loss',\n",
    "    title='learning rates'\n",
    ")\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(frame_count=n_frames).to(device)\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "optimiser = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "classifier = EpicActionRecogintionShapleyClassifier(model, dataloader, optimiser, device, log_interval=log_interval)\n",
    "data = iter(dataloader)\n",
    "inputs = data.next()\n",
    "\n",
    "\n",
    "out = classifier._step(inputs)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_sampler = RandomSampler(frame_count=n_frames, snippet_length=1, test=False)\n",
    "dataset = PickleDataset(pickle_dir, frame_sampler)\n",
    "\n",
    "validation_split = 0.2\n",
    "\n",
    "idxs = list(range(len(dataset)))\n",
    "split = int(np.floor(validation_split * len(dataset)))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "\n",
    "train_idx, test_idx = idxs[split:], idxs[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(train_loader)\n",
    "\n",
    "inputs = data.next()\n",
    "\n",
    "inputs\n",
    "# classifier.save_parameters('../datasets/epic/models/4-frame-trn-0_695.pt')\n",
    "# out = classifier._step(inputs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gulpio2 import GulpDirectory\n",
    "\n",
    "class GulpDataset(Dataset):\n",
    "\n",
    "    def __init__(self, gulp_dir: Path):\n",
    "        self.narration_ids = [],\n",
    "        self.gulp_data: GulpDirectory\n",
    "        self._load(gulp_dir)\n",
    "\n",
    "    def _load(self, gulp_dir: Path):\n",
    "        self.gulp_data = GulpDirectory(gulp_dir)\n",
    "        self.narration_ids = list(self.gulp_data.merged_meta_dict.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.narration_ids)\n",
    "\n",
    "    def __getitem__(self, key: int):\n",
    "        return self.gulp_data[self.narration_ids[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GulpDataset('../datasets/epic/gulp/rgb/rgb_test/')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, labels = dataset.gulp_data['P01_01_96']\n",
    "\n",
    "loader = iter(dataloader)\n",
    "inputs, labels = loader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels\n",
    "# inputs = torch.cat(inputs).to(dtype=torch.float)\n",
    "\n",
    "# inputs = inputs.index_select(0, torch.tensor([0,3,1,2]))\n",
    "# inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_collate(args):\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "frame_cumsum = np.array([0.])\n",
    "with open('../datasets/epic/features/tem_pickle.pkl', 'rb') as f:\n",
    "    pkl = pickle.load(f)\n",
    "    frame_counts = [label['num_frames'] for label in pkl['labels']]\n",
    "    frame_cumsum = np.cumsum(np.concatenate([frame_cumsum, frame_counts]), dtype=int)\n",
    "    \n",
    "key = 10\n",
    "\n",
    "def _video_from_narration_id(key: int):\n",
    "    l = frame_cumsum[key]\n",
    "    r = frame_cumsum[key+1]\n",
    "    return pkl['features'][l:r]\n",
    "\n",
    "features = _video_from_narration_id(10)\n",
    "\n",
    "features.shape, { k: pkl['labels'][key][k] for k in ['narration_id','verb_class','noun_class', 'num_frames'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class MultiPickleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, pkl_path: Path, features_dim: int = 256):\n",
    "        self.pkl_path = pkl_path\n",
    "        self.features_dim = features_dim\n",
    "        self.pkl_dict = Dict[str, Any]\n",
    "        self.frame_cumsum = np.array([0.])\n",
    "        self._load()\n",
    "        \n",
    "    def _load(self):\n",
    "        with open(self.pkl_path, 'rb') as f:\n",
    "            self.pkl_dict = pickle.load(f)\n",
    "            frame_counts = [label['num_frames'] for label in self.pkl_dict['labels']]\n",
    "            self.frame_cumsum = np.cumsum(np.concatenate([self.frame_cumsum, frame_counts]), dtype=int)\n",
    "    \n",
    "    def _video_from_narration_id(self, key: int):\n",
    "        l = self.frame_cumsum[key]\n",
    "        r = self.frame_cumsum[key+1]\n",
    "        return self.pkl_dict['features'][l:r]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_dict['narration_id'])\n",
    "    \n",
    "    def __getitem__(self, key: int):\n",
    "        features = self._video_from_narration_id(key)\n",
    "        video_length = features.shape[0]\n",
    "        assert video_length == self.pkl_dict['labels'][key]['num_frames']\n",
    "        \n",
    "        return (features, { k: self.pkl_dict['labels'][key][k] for k in ['narration_id','verb_class','noun_class'] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdataset = MultiPickleDataset('../datasets/epic/features/tem_pickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(mdataset, batch_size=64, collate_fn=no_collate, shuffle=True)\n",
    "frame_sampler = RandomSampler(frame_count=5, snippet_length=1, test=False)\n",
    "\n",
    "models = [Net(frame_count=i) for i in range(1,9)]\n",
    "optims = [Adam(m.parameters(), lr=1e-4) for m in models]\n",
    "f_samp = [RandomSampler(frame_count=m.frame_count, snippet_length=1, test=False) for m in models]\n",
    "\n",
    "from torchvideo.samplers import frame_idx_to_list\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "assert len(models) == len(optims)\n",
    "training_loss = {}\n",
    "testing_loss = {}\n",
    "for m, o, f in zip(models, optims, f_samp):\n",
    "    classifier = EpicActionRecogintionShapleyClassifier(m, device, o, None, None, log_interval=10)\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        logs = {}\n",
    "        running_loss = 0.0\n",
    "        running_acc1 = 0.0\n",
    "        running_acc5 = 0.0\n",
    "        for batch_idx, data in enumerate(dl):\n",
    "            features = []\n",
    "            labels = {}\n",
    "            for feature, label in data:\n",
    "                length = feature.shape[0]\n",
    "                if length < 5:\n",
    "                    raise ValueError('video too short')\n",
    "                idxs = np.array(frame_idx_to_list(f.sample(length)))\n",
    "                features.append(feature[idxs])\n",
    "                for k in label.keys():\n",
    "                    if k in labels:\n",
    "                        labels[k].append(label[k])\n",
    "                    else:\n",
    "                        labels[k] = [label[k]]\n",
    "\n",
    "            for k in labels.keys():\n",
    "                try:\n",
    "                    labels[k] = torch.tensor(labels[k])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            inputs = torch.tensor(features, dtype=dtype)\n",
    "\n",
    "            o.zero_grad()\n",
    "            step = classifier._step((inputs, labels))\n",
    "\n",
    "            loss = step['loss']\n",
    "            acc1 = step['verb_accuracy@1']\n",
    "            acc5 = step['verb_accuracy@5']\n",
    "\n",
    "            loss.backward()\n",
    "            o.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_acc1 += acc1.item()\n",
    "            running_acc5 += acc5.item()\n",
    "            if f'{m.frame_count}_loss' not in training_loss:\n",
    "                training_loss[f'{m.frame_count}_loss'] = [loss.item()]\n",
    "            else:\n",
    "                training_loss[f'{m.frame_count}_loss'].append(loss.item())\n",
    "            if f'{m.frame_count}_acc1' not in training_loss:\n",
    "                training_loss[f'{m.frame_count}_acc1'] = [acc1.item()]\n",
    "            else:\n",
    "                training_loss[f'{m.frame_count}_acc1'].append(acc1.item())\n",
    "            if f'{m.frame_count}_acc5' not in training_loss:\n",
    "                training_loss[f'{m.frame_count}_acc5'] = [acc5.item()]\n",
    "            else:\n",
    "                training_loss[f'{m.frame_count}_acc5'].append(acc5.item())\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(dl)\n",
    "        epoch_acc1 = running_acc1 / len(dl)\n",
    "        epoch_acc5 = running_acc5 / len(dl)\n",
    "        \n",
    "        logs[f'{m.frame_count}_loss'] = epoch_loss\n",
    "        logs[f'{m.frame_count}_accuracy'] = epoch_acc1\n",
    "        logs[f'{m.frame_count}_accuracy_5'] = epoch_acc5\n",
    "        \n",
    "        writer.add_scalar('loss', logs[f'{m.frame_count}_loss'], epoch)\n",
    "        \n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dl:\n",
    "    features = []\n",
    "    labels = {}\n",
    "#     labels = {k: [d[k] for d in labels] for k in d.keys()}\n",
    "    for feature, label in d:\n",
    "        length = feature.shape[0]\n",
    "        if length < 5:\n",
    "            raise ValueError('video too short')\n",
    "        idxs = np.array(frame_idx_to_list(frame_sampler.sample(length)))\n",
    "        features.append(feature[idxs])\n",
    "        for k in label.keys():\n",
    "            if k in labels:\n",
    "                labels[k].append(label[k])\n",
    "            else:\n",
    "                labels[k] = [label[k]]\n",
    "                \n",
    "    for k in labels.keys():\n",
    "        try:\n",
    "            labels[k] = torch.tensor(labels[k], device=device)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    inputs = torch.tensor(features, device=device)\n",
    "    \n",
    "    print(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(1,9):\n",
    "    y = training_loss[f'{i}_loss']\n",
    "    x = np.linspace(1, len(y), len(y))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=f'{i} frames'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='batched steps',\n",
    "    yaxis_title='loss',\n",
    "    title='training performance for mtrn'\n",
    ")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(1,9):\n",
    "    y = training_loss[f'{i}_acc1']\n",
    "    x = np.linspace(1, len(y), len(y))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=f'{i} frames'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='batched steps',\n",
    "    yaxis_title='accuracy',\n",
    "    title='accuracy performance for mtrn'\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(1,9):\n",
    "    y = training_loss[f'{i}_acc5']\n",
    "    x = np.linspace(1, len(y), len(y))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=f'{i} frames'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='batched steps',\n",
    "    yaxis_title='accuracy',\n",
    "    title='accuracy k=5 performance for mtrn'\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for i, d in enumerate(itertools.islice(dl, 1, len(dl))):\n",
    "    print(i, len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.pkl import PickleFeatureWriter\n",
    "from datasets.gulp_dataset import GulpDataset\n",
    "\n",
    "wr = PickleFeatureWriter('../datasets/epic/features/temp.pkl', features_dim=256)\n",
    "ds = GulpDataset('../datasets/epic/gulp/rgb/rgb_test/')\n",
    "idxs = torch.arange(20, len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ds = Subset(ds, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P01_01_0',\n",
       " 'P01_01_1',\n",
       " 'P01_01_10',\n",
       " 'P01_01_100',\n",
       " 'P01_01_101',\n",
       " 'P01_01_102',\n",
       " 'P01_01_103',\n",
       " 'P01_01_104',\n",
       " 'P01_01_105',\n",
       " 'P01_01_106',\n",
       " 'P01_01_107',\n",
       " 'P01_01_108',\n",
       " 'P01_01_109',\n",
       " 'P01_01_11',\n",
       " 'P01_01_110',\n",
       " 'P01_01_111',\n",
       " 'P01_01_112',\n",
       " 'P01_01_113',\n",
       " 'P01_01_114',\n",
       " 'P01_01_115',\n",
       " 'P01_01_116',\n",
       " 'P01_01_117',\n",
       " 'P01_01_118',\n",
       " 'P01_01_12',\n",
       " 'P01_01_120',\n",
       " 'P01_01_121',\n",
       " 'P01_01_122',\n",
       " 'P01_01_123',\n",
       " 'P01_01_124',\n",
       " 'P01_01_125',\n",
       " 'P01_01_126',\n",
       " 'P01_01_127',\n",
       " 'P01_01_128',\n",
       " 'P01_01_129',\n",
       " 'P01_01_13',\n",
       " 'P01_01_130',\n",
       " 'P01_01_131',\n",
       " 'P01_01_132',\n",
       " 'P01_01_133',\n",
       " 'P01_01_134',\n",
       " 'P01_01_135',\n",
       " 'P01_01_136',\n",
       " 'P01_01_137',\n",
       " 'P01_01_138',\n",
       " 'P01_01_139',\n",
       " 'P01_01_14',\n",
       " 'P01_01_140',\n",
       " 'P01_01_141',\n",
       " 'P01_01_142',\n",
       " 'P01_01_143',\n",
       " 'P01_01_144',\n",
       " 'P01_01_145',\n",
       " 'P01_01_146',\n",
       " 'P01_01_147',\n",
       " 'P01_01_148',\n",
       " 'P01_01_149',\n",
       " 'P01_01_15',\n",
       " 'P01_01_150',\n",
       " 'P01_01_151',\n",
       " 'P01_01_152',\n",
       " 'P01_01_153',\n",
       " 'P01_01_154',\n",
       " 'P01_01_155',\n",
       " 'P01_01_156',\n",
       " 'P01_01_157',\n",
       " 'P01_01_158',\n",
       " 'P01_01_159',\n",
       " 'P01_01_16',\n",
       " 'P01_01_160',\n",
       " 'P01_01_161',\n",
       " 'P01_01_162',\n",
       " 'P01_01_163',\n",
       " 'P01_01_164',\n",
       " 'P01_01_165',\n",
       " 'P01_01_166',\n",
       " 'P01_01_167',\n",
       " 'P01_01_168',\n",
       " 'P01_01_169',\n",
       " 'P01_01_17',\n",
       " 'P01_01_170',\n",
       " 'P01_01_171',\n",
       " 'P01_01_172',\n",
       " 'P01_01_173',\n",
       " 'P01_01_174',\n",
       " 'P01_01_175',\n",
       " 'P01_01_176',\n",
       " 'P01_01_177',\n",
       " 'P01_01_178',\n",
       " 'P01_01_179',\n",
       " 'P01_01_18',\n",
       " 'P01_01_180',\n",
       " 'P01_01_181',\n",
       " 'P01_01_182',\n",
       " 'P01_01_183',\n",
       " 'P01_01_184',\n",
       " 'P01_01_185',\n",
       " 'P01_01_186',\n",
       " 'P01_01_187',\n",
       " 'P01_01_188',\n",
       " 'P01_01_189',\n",
       " 'P01_01_19',\n",
       " 'P01_01_190',\n",
       " 'P01_01_191',\n",
       " 'P01_01_192',\n",
       " 'P01_01_193',\n",
       " 'P01_01_194',\n",
       " 'P01_01_195',\n",
       " 'P01_01_196',\n",
       " 'P01_01_197',\n",
       " 'P01_01_198',\n",
       " 'P01_01_199',\n",
       " 'P01_01_2',\n",
       " 'P01_01_20',\n",
       " 'P01_01_200',\n",
       " 'P01_01_201',\n",
       " 'P01_01_202',\n",
       " 'P01_01_203',\n",
       " 'P01_01_204',\n",
       " 'P01_01_205',\n",
       " 'P01_01_206',\n",
       " 'P01_01_207',\n",
       " 'P01_01_208',\n",
       " 'P01_01_209',\n",
       " 'P01_01_21',\n",
       " 'P01_01_210',\n",
       " 'P01_01_211',\n",
       " 'P01_01_212',\n",
       " 'P01_01_213',\n",
       " 'P01_01_214',\n",
       " 'P01_01_215',\n",
       " 'P01_01_216',\n",
       " 'P01_01_217',\n",
       " 'P01_01_218',\n",
       " 'P01_01_219',\n",
       " 'P01_01_22',\n",
       " 'P01_01_220',\n",
       " 'P01_01_221',\n",
       " 'P01_01_222',\n",
       " 'P01_01_223',\n",
       " 'P01_01_224',\n",
       " 'P01_01_225',\n",
       " 'P01_01_226',\n",
       " 'P01_01_227',\n",
       " 'P01_01_228',\n",
       " 'P01_01_229',\n",
       " 'P01_01_23',\n",
       " 'P01_01_230',\n",
       " 'P01_01_231',\n",
       " 'P01_01_232',\n",
       " 'P01_01_233',\n",
       " 'P01_01_234',\n",
       " 'P01_01_235',\n",
       " 'P01_01_236',\n",
       " 'P01_01_237',\n",
       " 'P01_01_238',\n",
       " 'P01_01_239',\n",
       " 'P01_01_24',\n",
       " 'P01_01_240',\n",
       " 'P01_01_241',\n",
       " 'P01_01_242',\n",
       " 'P01_01_243',\n",
       " 'P01_01_244',\n",
       " 'P01_01_245',\n",
       " 'P01_01_246',\n",
       " 'P01_01_247',\n",
       " 'P01_01_248',\n",
       " 'P01_01_249',\n",
       " 'P01_01_25',\n",
       " 'P01_01_250',\n",
       " 'P01_01_251',\n",
       " 'P01_01_252',\n",
       " 'P01_01_253',\n",
       " 'P01_01_254',\n",
       " 'P01_01_255',\n",
       " 'P01_01_256',\n",
       " 'P01_01_257',\n",
       " 'P01_01_258',\n",
       " 'P01_01_259',\n",
       " 'P01_01_26',\n",
       " 'P01_01_260',\n",
       " 'P01_01_261',\n",
       " 'P01_01_262',\n",
       " 'P01_01_263',\n",
       " 'P01_01_264',\n",
       " 'P01_01_265',\n",
       " 'P01_01_266',\n",
       " 'P01_01_267',\n",
       " 'P01_01_268',\n",
       " 'P01_01_269',\n",
       " 'P01_01_27',\n",
       " 'P01_01_270',\n",
       " 'P01_01_271',\n",
       " 'P01_01_272',\n",
       " 'P01_01_273',\n",
       " 'P01_01_274',\n",
       " 'P01_01_275',\n",
       " 'P01_01_276',\n",
       " 'P01_01_277',\n",
       " 'P01_01_278',\n",
       " 'P01_01_279',\n",
       " 'P01_01_28',\n",
       " 'P01_01_280',\n",
       " 'P01_01_281',\n",
       " 'P01_01_282',\n",
       " 'P01_01_283',\n",
       " 'P01_01_284',\n",
       " 'P01_01_285',\n",
       " 'P01_01_286',\n",
       " 'P01_01_287',\n",
       " 'P01_01_288',\n",
       " 'P01_01_289',\n",
       " 'P01_01_29',\n",
       " 'P01_01_290',\n",
       " 'P01_01_291',\n",
       " 'P01_01_292',\n",
       " 'P01_01_293',\n",
       " 'P01_01_294',\n",
       " 'P01_01_295',\n",
       " 'P01_01_296',\n",
       " 'P01_01_297',\n",
       " 'P01_01_298',\n",
       " 'P01_01_299',\n",
       " 'P01_01_3',\n",
       " 'P01_01_30',\n",
       " 'P01_01_300',\n",
       " 'P01_01_301',\n",
       " 'P01_01_302',\n",
       " 'P01_01_303',\n",
       " 'P01_01_304',\n",
       " 'P01_01_305',\n",
       " 'P01_01_306',\n",
       " 'P01_01_307',\n",
       " 'P01_01_308',\n",
       " 'P01_01_309',\n",
       " 'P01_01_31',\n",
       " 'P01_01_310',\n",
       " 'P01_01_311',\n",
       " 'P01_01_312',\n",
       " 'P01_01_313',\n",
       " 'P01_01_314',\n",
       " 'P01_01_315',\n",
       " 'P01_01_316',\n",
       " 'P01_01_317',\n",
       " 'P01_01_318',\n",
       " 'P01_01_319',\n",
       " 'P01_01_32',\n",
       " 'P01_01_320',\n",
       " 'P01_01_321',\n",
       " 'P01_01_322',\n",
       " 'P01_01_323',\n",
       " 'P01_01_324',\n",
       " 'P01_01_325',\n",
       " 'P01_01_326',\n",
       " 'P01_01_327',\n",
       " 'P01_01_328',\n",
       " 'P01_01_329',\n",
       " 'P01_01_33',\n",
       " 'P01_01_34',\n",
       " 'P01_01_35',\n",
       " 'P01_01_36',\n",
       " 'P01_01_37',\n",
       " 'P01_01_38',\n",
       " 'P01_01_39',\n",
       " 'P01_01_4',\n",
       " 'P01_01_40',\n",
       " 'P01_01_41',\n",
       " 'P01_01_42',\n",
       " 'P01_01_43',\n",
       " 'P01_01_44',\n",
       " 'P01_01_45',\n",
       " 'P01_01_46',\n",
       " 'P01_01_47',\n",
       " 'P01_01_48',\n",
       " 'P01_01_49',\n",
       " 'P01_01_5',\n",
       " 'P01_01_50',\n",
       " 'P01_01_51',\n",
       " 'P01_01_52',\n",
       " 'P01_01_53',\n",
       " 'P01_01_54',\n",
       " 'P01_01_55',\n",
       " 'P01_01_56',\n",
       " 'P01_01_57',\n",
       " 'P01_01_58',\n",
       " 'P01_01_59',\n",
       " 'P01_01_6',\n",
       " 'P01_01_60',\n",
       " 'P01_01_61',\n",
       " 'P01_01_62',\n",
       " 'P01_01_63',\n",
       " 'P01_01_64',\n",
       " 'P01_01_65',\n",
       " 'P01_01_66',\n",
       " 'P01_01_67',\n",
       " 'P01_01_68',\n",
       " 'P01_01_69',\n",
       " 'P01_01_7',\n",
       " 'P01_01_70',\n",
       " 'P01_01_71',\n",
       " 'P01_01_72',\n",
       " 'P01_01_73',\n",
       " 'P01_01_74',\n",
       " 'P01_01_75',\n",
       " 'P01_01_76',\n",
       " 'P01_01_77',\n",
       " 'P01_01_78',\n",
       " 'P01_01_79',\n",
       " 'P01_01_8',\n",
       " 'P01_01_80',\n",
       " 'P01_01_81',\n",
       " 'P01_01_82',\n",
       " 'P01_01_83',\n",
       " 'P01_01_84',\n",
       " 'P01_01_85',\n",
       " 'P01_01_86',\n",
       " 'P01_01_87',\n",
       " 'P01_01_88',\n",
       " 'P01_01_89',\n",
       " 'P01_01_9',\n",
       " 'P01_01_90',\n",
       " 'P01_01_91',\n",
       " 'P01_01_92',\n",
       " 'P01_01_93',\n",
       " 'P01_01_94',\n",
       " 'P01_01_95',\n",
       " 'P01_01_96',\n",
       " 'P01_01_97',\n",
       " 'P01_01_98',\n",
       " 'P01_01_99']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.narration_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3617, 256)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../datasets/epic/features/tem_pickle.pkl', 'rb') as f:\n",
    "    xallow = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
